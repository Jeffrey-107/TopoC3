{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a947ba4-927d-4b83-b8bb-3aba51c3b90f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc76869-dbd6-4982-8630-07ced7454e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from Element_PI import VariancePersist\n",
    "from Element_PI import VariancePersistv1\n",
    "from scipy.stats import randint, uniform, rv_continuous\n",
    "from scipy.stats._distn_infrastructure import rv_continuous\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415151b-55ee-4093-bb8d-21d479c8ad36",
   "metadata": {},
   "source": [
    "# (X) Elemental Persistence Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3be54f-afcb-4241-8046-aed526af4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PI hyperparameters\n",
    "pixelsx = 55\n",
    "pixelsy = 55\n",
    "spread = 3.0\n",
    "Max = 3.5\n",
    "\n",
    "# Get list of XYZ files\n",
    "files = glob.glob('XYZ_DIRECTORY/*.xyz')\n",
    "samples = len(files)\n",
    "\n",
    "# Initialize X\n",
    "X = np.zeros((samples, pixelsx * pixelsy))\n",
    "\n",
    "# Iterate over files\n",
    "for idx, file in enumerate(files):\n",
    "    X[idx, :] = VariancePersistv1(file, pixelx=pixelsx, pixely=pixelsy, myspread=spread, myspecs={\"maxBD\": Max, \"minBD\": -0.10}, showplot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8c2c1-6e42-4a8d-89b9-6a6944764e88",
   "metadata": {},
   "source": [
    "# (y) Enthalpy Values Corresponding to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a01dff-3808-4b07-8e46-592a63f716d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "csv_file_path = \"CSV_FILENAME.csv\"  # Replace with the actual path to the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get the list of XYZ files in the xyz directory\n",
    "molecules_directory = \"./XYZ_DIRECTORY\"  # Replace with the actual path to the xyz directory\n",
    "xyz_files = [file for file in os.listdir(molecules_directory) if file.endswith(\".xyz\")]\n",
    "\n",
    "# Filter the DataFrame to include only the rows where XYZ file names are present in the list of XYZ files\n",
    "filtered_df = df[df['Filename'].isin(xyz_files)]\n",
    "\n",
    "# Reindex the DataFrame to match the order of XYZ files obtained from the directory\n",
    "ordered_df = filtered_df.set_index('Filename').reindex(xyz_files).reset_index()\n",
    "\n",
    "# Print the ordered DataFrame\n",
    "print(ordered_df)\n",
    "\n",
    "# Extract the \"H\" column values from the ordered DataFrame\n",
    "y = ordered_df['H'].values\n",
    "\n",
    "# Print the energy values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221cb07-474c-4481-8e5c-f16f94e41df7",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression with Hyperparameter Scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e836f0-ec5a-4fdb-a8a4-7a6560ae2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "\n",
    "def test_learner(X, y, model):\n",
    "    kf = KFold(n_splits=3, random_state=0, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    errorlist = []\n",
    "    mdscr_list = []\n",
    "    r2_train_list = []  # List to store R-squared values of the training set across folds\n",
    "    r2_test_list = []   # List to store R-squared values of the testing set across folds\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Flatten the matrices to make them 2D arrays\n",
    "        X_train_flat = np.array([matrix.flatten() for matrix in X_train])\n",
    "        X_test_flat = np.array([matrix.flatten() for matrix in X_test])\n",
    "\n",
    "        # Train the model on the entire training set\n",
    "        model.fit(X_train_flat, y_train)\n",
    "\n",
    "        # Calculate error on the entire testing set\n",
    "        error = rmse(model.predict(X_test_flat), y_test)\n",
    "        errorlist.append(error)\n",
    "\n",
    "        # Calculate scores and errors for training set\n",
    "        tr = model.score(X_train_flat, y_train)\n",
    "        te = model.score(X_test_flat, y_test)\n",
    "\n",
    "        # Store R-squared values for training and testing sets\n",
    "        r2_train_list.append(tr)\n",
    "        r2_test_list.append(te)\n",
    "\n",
    "        # Print metrics for each fold\n",
    "        print('Fold error {} for fold {}'.format(error, fold))\n",
    "        print(tr, 'is the score for the training set')\n",
    "        print(te, 'is the score for the testing set')\n",
    "        print(\"Size of Training Set:\", len(y_train))\n",
    "        print(\"Size of Testing Set:\", len(y_test))\n",
    "        print()\n",
    "\n",
    "        # Plotting for each fold\n",
    "        plt.scatter(y_train.flatten(), model.predict(X_train_flat), color=\"b\", label='Training Set')\n",
    "        plt.scatter(y_test.flatten(), model.predict(X_test_flat), color=\"r\", label='Testing Set')\n",
    "        # Plot the diagonal line\n",
    "        plt.plot([min(y_test.flatten()), max(y_test.flatten())], [min(y_test.flatten()), max(y_test.flatten())], '--', color='rebeccapurple')\n",
    "        plt.legend(fontsize=12, loc=\"lower right\")\n",
    "        plt.ylabel('Predicted Enthalpy (kcal/mol)', fontsize=12)\n",
    "        plt.xlabel('DFT Enthalpy (kcal/mol)', fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate R-squared score for the current fold\n",
    "        fold_mdscr = (tr + te) / 2\n",
    "        mdscr_list.append(fold_mdscr)\n",
    "\n",
    "    # Print averages across all folds\n",
    "    print('Final error {} +- {} '.format(np.average(errorlist), np.std(errorlist)))\n",
    "    \n",
    "    # Overall model score\n",
    "    mdscr = np.mean(mdscr_list)\n",
    "    print(mdscr, \"is the score for the model\")\n",
    "\n",
    "    # Print mean of R-squared scores from each fold\n",
    "    mean_mdscr = np.mean(mdscr_list)\n",
    "    print(mean_mdscr, \"is the mean of R-squared scores from each fold\")\n",
    "\n",
    "    # Print average R-squared values of training and testing sets across all folds\n",
    "    avg_r2_train = np.mean(r2_train_list)\n",
    "    avg_r2_test = np.mean(r2_test_list)\n",
    "    print(\"Average R-squared on Training Set (across all folds):\", avg_r2_train)\n",
    "    print(\"Average R-squared on Testing Set (across all folds):\", avg_r2_test)\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Hyperparameter scan (alpha, gamma) with one-standard-error rule\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def mean_test_r2_for_params(X, y, alpha, gamma, splits=None):\n",
    "    \"\"\"Compute mean test R^2 across provided CV splits for given alpha, gamma.\"\"\"\n",
    "    if splits is None:\n",
    "        kf = KFold(n_splits=3, random_state=0, shuffle=True)\n",
    "        splits = list(kf.split(X))\n",
    "    r2_test_list = []\n",
    "    for train_index, test_index in splits:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Flatten to 2D arrays (same as in test_learner)\n",
    "        X_train_flat = np.array([matrix.flatten() for matrix in X_train])\n",
    "        X_test_flat = np.array([matrix.flatten() for matrix in X_test])\n",
    "\n",
    "        model = KernelRidge(alpha=alpha, kernel='laplacian', gamma=gamma)\n",
    "        model.fit(X_train_flat, y_train)\n",
    "        te = model.score(X_test_flat, y_test)  # R^2 on test\n",
    "        r2_test_list.append(te)\n",
    "    return float(np.mean(r2_test_list)), float(np.std(r2_test_list))\n",
    "\n",
    "\n",
    "def run_hyperparameter_scan(X, y, alpha_grid, gamma_grid, folds=3):\n",
    "    \"\"\"Grid search over alpha and gamma; returns (best_params, results).\"\"\"\n",
    "    kf = KFold(n_splits=folds, random_state=0, shuffle=True)\n",
    "    splits = list(kf.split(X)) \n",
    "\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    results = []  # collect all results: (alpha, gamma, mean_r2, std_r2)\n",
    "\n",
    "    for alpha in alpha_grid:\n",
    "        for gamma in gamma_grid:\n",
    "            mean_r2, std_r2 = mean_test_r2_for_params(X, y, alpha, gamma, splits=splits)\n",
    "            results.append((alpha, gamma, mean_r2, std_r2))\n",
    "            print(f\"alpha={alpha:.6g}, gamma={gamma:.6g} -> mean test R^2={mean_r2:.4f} Â± {std_r2:.4f}\")\n",
    "            if mean_r2 > best_score:\n",
    "                best_score = mean_r2\n",
    "                best_params = (alpha, gamma)\n",
    "\n",
    "    print(\"\\nBest-by-mean params (raw scan):\")\n",
    "    print(f\"alpha={best_params[0]:.6g}, gamma={best_params[1]:.6g} with mean test R^2={best_score:.4f}\")\n",
    "    return best_params, results\n",
    "\n",
    "\n",
    "def select_params_one_se(results, folds=3):\n",
    "    \"\"\"\n",
    "    Apply one-standard-error rule.\n",
    "    results: list of tuples (alpha, gamma, mean_r2, std_r2)\n",
    "    folds: number of CV folds used to compute mean/std\n",
    "    Returns (alpha, gamma) chosen by the one-standard-error rule,\n",
    "    preferring larger alpha and smaller gamma (simpler models).\n",
    "    \"\"\"\n",
    "    # Best mean score and its SE\n",
    "    best = max(results, key=lambda r: r[2])\n",
    "    best_mean, best_std = best[2], best[3]\n",
    "    best_se = best_std / np.sqrt(folds)\n",
    "    threshold = best_mean - best_se\n",
    "\n",
    "    # Candidates within one SE of the best\n",
    "    candidates = [r for r in results if r[2] >= threshold]\n",
    "\n",
    "    # Choose \"simplest\": larger alpha, then smaller gamma\n",
    "    candidates.sort(key=lambda r: (r[0], -r[1]), reverse=True)\n",
    "    chosen = candidates[0]\n",
    "    print(f\"One-SE choice: alpha={chosen[0]:.6g}, gamma={chosen[1]:.6g} \"\n",
    "          f\"(mean R^2={chosen[2]:.4f}, std={chosen[3]:.4f}; threshold={threshold:.4f})\")\n",
    "    return chosen[0], chosen[1]\n",
    "\n",
    "\n",
    "# Example grids (adjust as needed)\n",
    "alpha_grid = np.logspace(-4, 0, 50)  # 1e-4 to 1, log-spaced\n",
    "gamma_grid = np.logspace(-4, 0, 50)  # 1e-4 to 1, log-spaced\n",
    "\n",
    "# Run scan, then apply one-standard-error selection\n",
    "_, results = run_hyperparameter_scan(X, np.array(y), alpha_grid, gamma_grid, folds=3)\n",
    "alpha_1se, gamma_1se = select_params_one_se(results, folds=3)\n",
    "\n",
    "# Final model using one-SE params\n",
    "model = KernelRidge(alpha=alpha_1se, kernel='laplacian', gamma=gamma_1se)\n",
    "test_learner(X, np.array(y), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d8b7e-e5b6-489b-bead-dbeb1e88545e",
   "metadata": {},
   "source": [
    "# Make Predictions on Large Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce4430-5a0c-4941-ac7c-c1043d3148c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing XYZ files for validation\n",
    "xyz_directory = \"DATABASE_DIRECTORY\"  # Replace witH actual directory\n",
    "xyz_files = [os.path.join(xyz_directory, file) for file in os.listdir(xyz_directory) if file.endswith(\".xyz\")]\n",
    "\n",
    "# Define PI hyperparameters\n",
    "pixelsx = 55\n",
    "pixelsy = 55\n",
    "spread = 3.0\n",
    "Max = 3.5\n",
    "\n",
    "# Initialize a dictionary to store filename and predicted energy pairs\n",
    "filename_energy_dict = {}\n",
    "\n",
    "# Initialize list to store feature vectors (optional)\n",
    "X_list = []\n",
    "\n",
    "# Iterate over xyz files\n",
    "for idx, xyz_file in enumerate(xyz_files):\n",
    "    xyz_file_name = os.path.basename(xyz_file)\n",
    "\n",
    "    try:\n",
    "        # Generate Persistence Image vector using VariancePersistv1\n",
    "        pi_vector = VariancePersistv1(\n",
    "            xyz_file,\n",
    "            pixelx=pixelsx,\n",
    "            pixely=pixelsy,\n",
    "            myspread=spread,\n",
    "            myspecs={\"maxBD\": Max, \"minBD\": -0.10},\n",
    "            showplot=False\n",
    "        )\n",
    "\n",
    "        # Append to X_list (optional, for further analysis)\n",
    "        X_list.append(pi_vector)\n",
    "\n",
    "        # Prediction\n",
    "        predicted_energy = model.predict(pi_vector.reshape(1, -1))[0]\n",
    "\n",
    "        # Store filename and predicted energy\n",
    "        filename_energy_dict[xyz_file_name] = predicted_energy\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print the filename that caused any error and continue\n",
    "        print(f\"Error processing '{xyz_file_name}': {e}\")\n",
    "        continue\n",
    "\n",
    "# Sort the dictionary by predicted energy values (ascending)\n",
    "sorted_filename_energy = sorted(\n",
    "    filename_energy_dict.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=False\n",
    ")\n",
    "\n",
    "# Save ALL predictions into a CSV file\n",
    "csv_filename = \"NAME_OF_CSV_WITH_PREDICTIONS.csv\"\n",
    "with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Filename\", \"Predicted_Energy\"])  # Header for columns\n",
    "    for filename, energy in sorted_filename_energy:\n",
    "        writer.writerow([filename, energy])\n",
    "\n",
    "print(f\"\\nAll predictions saved to '{csv_filename}'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
